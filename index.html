<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<script>
// Set the date we're counting down to
var countDownDate = new Date("2022-05-23T08:30:00.000-04:00");
// Update the count down every 1 second
var x = setInterval(function() {

  // Get today's date and time
  var now = new Date().getTime();

  // Find the distance between now and the count down date
  var distance = countDownDate - now;

  // Time calculations for days, hours, minutes and seconds
  var days = Math.floor(distance / (1000 * 60 * 60 * 24));
  var hours = Math.floor((distance % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60));
  var minutes = Math.floor((distance % (1000 * 60 * 60)) / (1000 * 60));
  var seconds = Math.floor((distance % (1000 * 60)) / 1000);

  // Display the result in the element with id="demo"
  document.getElementById("demo").innerHTML = days + "d " + hours + "h "
  + minutes + "m " + seconds + "s ";

  // If the count down is finished, write some text
  if (distance < 0) {
    clearInterval(x);
    document.getElementById("demo").innerHTML = "EXPIRED";
  }
}, 1000);
</script>


<html>
	<head>
		<title>Workshop ICRA 2023</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<!-- table style-->
		<style>
			a{
				color: white; 
			}
			#schedule_tab {
			  font-family: Arial, Helvetica, sans-serif;
			  border-collapse: collapse;
			  width: 100%;
			}

			#schedule_tab td, #schedule_tab th {
			  border: 2px solid #ddd;
			  padding: 14px;
			  color: white;
			}

			#schedule_tab tr:nth-child(even){background-color: #9fabbd;}
			
			#schedule_tab tr:hover {background-color: #a8b9d2;}

			#schedule_tab th {
			  padding-top: 12px;
			  padding-bottom: 12px;
			  text-align: left;
			  background-color: #374e73;
			  color: white;
			}
		</style>
	</head>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#intro">Home</a></li>
							<li><a href="#content">Content</a></li>
							<li><a href="#schedule">Schedule</a></li>	
							<li><a href="#papers">Call for Papers</a></li>
							
							<li><a href="#talks">Invited speakers</a></li>
							<li><a href="#org">Organizers</a></li>	
							<!--li><a href="#collab">Links</a></li-->														
							<li><a href="#contact">Contact</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Live -->
					<!--section id="live" class="wrapper style3 fullscreen fade-up">
						<div class="inner">
							<h2>2nd Workshop on Representing and Manipulating Deformable Objects @ <a href="https://www.icra2022.org/">ICRA2022</a> </h2>
							
							


						</div>
					</section-->

<!-- Intro -->
					<section id="intro" class="wrapper style1 fullscreen fade-up">
						<div class="inner">

							<!--h1 id="demo"></h1-->

							<h2>3rd Workshop on Representing and Manipulating Deformable Objects @ <a href="https://www.icra2023.org/" target="_blank">ICRA2023</a> </h2> <!--  was held on 23.05.2022 8:30 GMT-04, Room 113C</h2-->

							<!--iframe width="560" height="315" src="https://www.youtube.com/embed/EVAXd6waVqg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe-->
							
							
							
							<p>
							Clothes, food, cables, and body tissue are just a few examples of deformable objects (DO) involved in both everyday and specialized tasks. Although humans are able to reliably manipulate them, automating this process using robotic platforms is still unsolved. Indeed, the high number of degrees of freedom involved in DOs undermines the effectiveness of traditional modelling, planning and control methods developed for rigid object manipulation. This paves the way for exciting questions from a research and application perspective. i) How to tractably represent the state of a deformable object? ii) How to model and simulate its highly complex and non-linear dynamics? iii) What hardware tools and platforms are best suited for grasping and manipulating? We aim to discuss these and more challenges that arise from handling deformable objects by connecting scientists from different subfields of robotics, including perception, simulation, control, and mechanics. Following the previous editions of the workshop at ICRA 2021 and ICRA 2022, the objective for the proposed third edition is to further identify promising research directions and analyze current state-of-the-art solutions with an emphasis on highlighting recent results since the 2022 workshop. We plan to facilitate this through invited talks and will foster new collaborations to connect young researchers with senior ones. 
							</p>
							
							
							
							<!--h3> The workshop was held in <b>hybrid mode</b> with free remote participation</h3-->
							<h3> The workshop will be held in <b>hybrid mode</b> </h3>
							
							<h3> Links: </h3>
							<ul id="link_list">
							<!--li> Slido link: <a href="https://app.sli.do/event/jnvdiJuTt848jpdvFqKZgu" target="_blank">https://app.sli.do/event/jnvdiJuTt848jpdvFqKZgu</a>  </li>
							<li> Zoom link:  <a href="https://zoom.us/j/7853144045?pwd=WlJ6bWQxQWlpTnlmNFpvNTVMWjlLUT09" target="_blank">https://zoom.us/j/7853144045?pwd=WlJ6bWQxQWlpTnlmNFpvNTVMWjlLUT09</a> </li-->
							<!--li> YouTube streaming: <a href="https://youtu.be/Ir0hUawBWrQ" target="_blank">https://youtu.be/Ir0hUawBWrQ</a>  </li-->
							<li> YouTube channel: <a href="https://www.youtube.com/channel/UCQFAnfbQK45enYDr8B0VdKw" target="_blank">https://www.youtube.com/channel/UCQFAnfbQK45enYDr8B0VdKw</a>  </li-->
							<li>Link to 2nd edition of the workshop: <a href="https://deformable-workshop.github.io/icra2022/" target="_blank">https://deformable-workshop.github.io/icra2022/</a></li>
							<li>Link to 1st edition of the workshop: <a href="https://deformable-workshop.github.io/icra2021/" target="_blank">https://deformable-workshop.github.io/icra2021/</a></li>
							
							</ul>
							
							


						</div>
					</section>


				

					<!-- Method -->
					<section id="content" class="wrapper style2 fade-up">
						<div class="inner">
							<h2>Content</h2>
							<h3>Topics</h3>

							<p> 
								The workshop aims to explore different aspects that will potentially allow robots to autonomously manipulate deformable objects in the near future. Enabling such manipulation is crucial for a variety of domains and tasks, e.g., domestic, industrial and surgical contexts, which involve various forms of object deformability. However, the complexity of representing and modeling the dynamics of these objects results in the lack of a current unified solution that can be adapted to a wide range of objects.
Specifically, the workshop will focus on, but is not limited to, the following topics for deformable object manipulation:


<ul>
  <li>Representation and state estimation</li>
  <li> Simulation and modeling </li>
  <li>Transfer from simulation to reality</li>
  <li>Learning to manipulate using data-driven methods such as reinforcement learning and learning from demonstrations </li>
  <li>Perception: state tracking, parameter identification, property detection (e.g. landmarks for
garments) and classification, etc. </li>
  <li>Control, visual servoing and planning</li>
  <li>Specialized tools, e.g. grippers, and sensors</li>
	<li>Multi-arm manipulation</li>
  <li>Application-specific challenges: cloth folding, surgical tasks, precision agriculture, etc.</li>
</ul>
							
							</p>

							
							
							<p> </p>	
<!--
							<h3>Workshop format </h3>
						<p>
						The workshop will include: 
<ul><li>Invited talks by selected speakers, each consisting of about 25 minutes of live presentation followed by 5 minutes for Q&A;<\li> 
<li>Accepted extended abstracts (3 pages with unlimited references and appendix) presented in poster sessions and selected spotlight talks. In case of a hybrid or virtual workshop, we will ask for pre-recorded spotlight talks for a smoother execution in case of connection issues. However, for each selected contribution, at least one author will be required to be present during the workshop for a live Q&A session;  </li>
<li>A group discussion session where different discussion groups will be formed from the attendees. Each group will be moderated by an organizer and will focus on a specific topic in the scope of the workshop. Moreover, organizers will annotate relevant insights during the discussions and will share them with the entire audience during the last part of this session. If a virtual component exists, we will facilitate participation with the help of breakout rooms.  </li>
<li>A panel discussion at the end of the workshop, moderated by the organizers,  for discussing challenges and promising directions for deformable object manipulation with experts of the field. Speakers will be informed in advance of the selected topics to make the discussion more effective. 
	</p>
-->

						</div>
					</section>


				<!-- Schedule -->
					<section id="schedule" class="wrapper style3 spotlights">
						<div class="inner">
							<h2>Schedule - (Tentative) <!-- a href="schedule_poster_panel.pdf" target="_blank">[PDF]</a--></h2>
							<hr style="width:80%;text-align:left;margin-left:5">
							<div class="row">
							  
									<!--p></p>
				    				<h3><b> TBA </b></h3>--> 
									
							</div>
							
							<h3>Time Zone: GMT-04</h3>
							<table id="schedule_tab">
						  <tr>
						    <th>Time</th>
						    <th>Activity</th>
						  </tr>
						  <tr>
						    <td>08:45 - 09:00</td>
						    <td>Workshop opening </td>
						  </tr>
						  <tr>
						    <td>09:00 - 09:30</td>
						    <td> <b>Yashraj Narang:</b> Simulated, Learned, and Differentiable Models for Deformable-Object Manipulation 
								</td>
						  </tr>
						  <tr>
						    <td>09:30 - 10:00</td>
						    <td> <b>Jia Pan:</b> Nonprehensile manipulation of cloth pieces </td>
						  </tr>
						  <tr>
						    <td>10:00 - 10:30</td>
						    <td>Spotlight talks #1 
								
						    </td>
						  </tr>
						  <tr>
						    <td>10:30 - 11:00</td>
						    <td>Coffee break  + Posters session #1
						    	

						    </td>
						  </tr>
						  <tr>
						    <td>11:00 – 11:30</td>
						    <td> <b> Yiannis Demiris:</b> Robot-assisted Dressing: bimanual policies for deformable object manipulation </td>
						  </tr>
						  <tr>
						    <td>11:30 – 12:00</td>
						    <td> <b>Elena De Momi:</b> AI-based techniques for improving tool-tissue interaction in robotic surgery </td>
						  </tr>
						 
						  <tr>
						    <td>12:00 - 13:00</td>
						    <td>Lunch </td>
						  </tr>
						  <tr>
						    <td>13:00 – 13:30</td>
						    <td> <b>Jihong Zhu: </b> Deformable Object Manipulation: Fundamental challenges and promising applications </td>
						  </tr>
						  <tr>
						    <td>13:30 – 14:00</td>
						    <td> 
										<b> Carme Torras: </b> Cloth representation and manipulation within the CLOTHILDE project
						    <b> </td>
						  </tr>
						  <tr>
						    <td>14:00 – 14:45</td>
						    <td>Spotlight talks #2 
						    	

						    </td>
						  </tr>
						  <tr>
						    <td>14:45- 15:30</td>
						    <td>Coffee break  + Posters session #2
						    

						    </td>
						  </tr>
						  <tr>
						    <td>15:30 – 16:00</td>
						    <td><b> Yunzhu Li:</b> Structured Model Learning for Deformable Object Manipulation </td>
						  </tr>
						  <tr>
						  
						    <td>16:30 – 17:00</td>
						    <td><b> Nima Fazeli:</b> Recent advances in Multimodal Implicit Representations of Deformable Objects </td>
						  </tr>
						  <tr>
						    <td>17:00 – 17:45</td>
						    <td>Panel discussion </td>
						  </tr>
						  <tr>
						    <td>17:45 – 18:00</td>
						    <td>Closing remarks</td>
						  </tr>
						</table>
						
							
						


					</section>
























					<!-- call for papers -->
					<section id="papers" class="wrapper style4 fullscreen fade-up">
						<div class="inner">
							<h2>Call for papers</h2>					
							
							
							<p> We invite participants to submit extended abstracts <b>3+n</b> pages, with n pages (no page-limit) for the bibliography, in the <a href="https://journals.ieeeauthorcenter.ieee.org">IEEE conference style</a>. </p>
							<p> Submissions will be reviewed by experts of their respective field. The accepted abstracts will be made available on the workshop website but will not appear in the official IEEE conference proceedings. 
							 Participants are encouraged to submit their recent work on the topics of interest mentioned above. 
							<!--contributions that highlight challenges in their particular sub-field as well as works that show potential synergies of combining different subfields for deformable objects manipulation. -->
							Contributions are encouraged, but are not required, to be original. </p>
							<p> The review process will be single-blind, meaning the submitted paper does not need to be anonymized.</p>
							<p> Abstracts can be submitted through Microsoft CMT: <a href="https://cmt3.research.microsoft.com/WDOICRA2023" target="_blank" class="to-red-mobile">https://cmt3.research.microsoft.com/WDOICRA2023</a>.
							</p>
							

							<p> <h3>Important dates: </h3>

							<ul>
								  <li>Submission Deadline: <b>10.04.2023 (23:59 PST) </b></li>
								  <li>Notification date: <b>30.04.2023 (23:59 PST) </b></li>
								  <li>Final submission: <b>14.05.2023 (23:59 PST) </b></li>
								  <li>Workshop date: <b> 29.05.2023 </b> 
 </li>
							</ul>

							</p>
							
							


						</div>
					</section>



					<!-- Schedule -->
					<section id="talks" class="wrapper style2 spotlights">
						<div class="inner">
							<h2>Invited Speakers (alphabetical order) </h2>
							<!--ul>
							<li>Yiannis Demiris, Professor, Imperial College London, UK</li>
							<li>Elena De Momi, Professor, Politecnico di Milano, Italy</li>
							<li>Nima Fazeli, Assistant Professor, University of Michigan, USA</li>
							<li>Yunzhu Li, (Incoming) Assistant Professor, University of Illinois Urbana-Champaign, USA</li>
							<li>Yashraj Narang (tentative), Senior Research Scientist, NVIDIA, USA</li>
							<li>Jia Pan, Assistant Professor, University of Hong Kong, China</li>
							<li>Carme Torras, Professor, Institut de Robòtica i Informàtica Industrial, Spain</li>
							<li>Jihong Zhu, Assistant Professor, University of York, UK</li>

							</ul-->

							<div class="row">
							  <div class="column">
							    <img src="imgs/Yiannis_Demiris.jpg" alt=" Yiannis Demiris" class="img-list">
							  </div>
							  <div class="column">
									<p></p>
				    				<h3 class='name-list'><b>  Yiannis Demiris </b></h3> 
									
				    				<div class='info-list'>
									<br> 
									 Professor
									<br>
									 Imperial College London, UK
									<br>
									<a href="https://www.imperial.ac.uk/people/y.demiris" target="_blank">Personal website</a>  
									<br>	
									</div>
									<p class='talk-list'>
									<b> Talk title:</b> Robot-assisted Dressing: bimanual policies for deformable object manipulation <br>
									</p>
							  </div>
							</div>

							<hr style="width:80%;text-align:left;margin-left:5">


							<div class="row">
							  <div class="column">
							    <img src="imgs/Elena_De_Momi.jpeg" alt="Elena De Momi" class="img-list">
							  </div>
							  <div class="column">
									<p></p>
				    				<h3 class='name-list'><b>  Elena De Momi </b></h3> 
									
				    				<div class='info-list'>
									<br> 
									Professor
									<br>
									Politecnico di Milano, Italy
									<br>
									<a href="https://www.deib.polimi.it/eng/people/details/172386" target="_blank">Personal website</a>  
									<br>	
									</div>
									<p class='talk-list'>
									<b> Talk title:</b> AI-based techniques for improving tool-tissue interaction in robotic surgery <br>
									</p>
							  </div>
							</div>

							<hr style="width:80%;text-align:left;margin-left:5">

							<div class="row">
							  <div class="column">
							    <img src="imgs/Nima_Fazeli.png" alt="Nima Fazeli" class="img-list">
							  </div>
							  <div class="column">
									<p></p>
				    				<h3 class='name-list'><b>  Nima Fazeli</b></h3> 
									
				    				<div class='info-list'>
									<br> 
									Assistant Professor
									<br>
									University of Michigan, USA
									<br>
									<a href="https://www.mmintlab.com/people/nima-fazeli/" target="_blank">Personal website</a>  
									<br>	
									</div>
									<p class='talk-list'>
									<b> Talk title:</b> Recent advances in Multimodal Implicit Representations of Deformable Objects <br>
									</p>
							  </div>
							</div>
						
							<hr style="width:80%;text-align:left;margin-left:5">

							<div class="row">
							  <div class="column">
							    <img src="imgs/Yunzhu_Li.jpeg" alt="Yunzhu Li" class="img-list">
							  </div>
							  <div class="column">
									<p></p>
				    				<h3 class='name-list'><b>  Yunzhu Li </b></h3> 
									
				    				<div class='info-list'>
									<br> 
									Postdoctoral Researcher
									<br>
									 Stanford, USA
									<br>
									<a href="https://yunzhuli.github.io/" target="_blank">Personal website</a>  
									<br>	
									</div>
									<p class='talk-list'>
									<b> Talk title:</b> Structured Model Learning for Deformable Object Manipulation <br>
									</p>
							  </div>
							</div>

								<hr style="width:80%;text-align:left;margin-left:5">

							<div class="row">
							  <div class="column">
							    <img src="imgs/Yashraj_Narang.jpeg" alt="Yashraj Narang" class="img-list">
							  </div>
							  <div class="column">
									<p></p>
				    				<h3 class='name-list'><b>  Yashraj Narang </b></h3> 
									
				    				<div class='info-list'>
									<br> 
									 Senior Research Scientist
									<br>
									NVIDIA, USA
									<br>
									<a href="https://scholar.google.com/citations?user=M3NuG7AAAAAJ&hl=en" target="_blank">Personal website</a>  
									<br>	
									</div>
									<p class='talk-list'>
									<b> Talk title:</b> Simulated, Learned, and Differentiable Models for Deformable-Object Manipulation <br>
									</p>
							  </div>
							</div>


							<hr style="width:80%;text-align:left;margin-left:5">


							<div class="row">
							  <div class="column">
							    <img src="imgs/Jia_Pan.jpg" alt="Jia Pan" class="img-list">
							  </div>
							  <div class="column">
									<p></p>
				    				<h3 class='name-list'><b>  Jia Pan </b></h3> 
									
				    				<div class='info-list'>
									<br> 
									Assistant Professor
									<br>
									University of Hong Kong, China
									<br>
									<a href="https://sites.google.com/site/panjia/" target="_blank">Personal website</a>  
									<br>	
									</div>
									<p class='talk-list'>
									<b> Talk title:</b> Nonprehensile manipulation of cloth pieces <br>
									</p>
							  </div>
							</div>

							<hr style="width:80%;text-align:left;margin-left:5">


							<div class="row">
							  <div class="column">
							    <img src="imgs/Carme_Torras.jpg" alt="Carme Torras" class="img-list">
							  </div>
							  <div class="column">
									<p></p>
				    				<h3 class='name-list'><b>  Carme Torras </b></h3> 
									
				    				<div class='info-list'>
									<br> 
									Professor 
									<br>
									 Institut de Robòtica i Informàtica Industrial, Spain
									<br>
									<a href="https://www.iri.upc.edu/people/torras/" target="_blank">Personal website</a>  
									<br>	
									</div>
									<p class='talk-list'>
									<b> Talk title:</b> Cloth representation and manipulation within the CLOTHILDE project <br>
									</p>
							  </div>
							</div>

							<hr style="width:80%;text-align:left;margin-left:5">


							<div class="row">
							  <div class="column">
							    <img src="imgs/Jihong_Zhu.jpg" alt="Jihong Zhu" class="img-list">
							  </div>
							  <div class="column">
									<p></p>
				    				<h3 class='name-list'><b>  Jihong Zhu </b></h3> 
									
				    				<div class='info-list'>
									<br> 
									Assistant Professor
									<br>
									University of York, UK
									<br>
									<a href="https://jihong-zhu.github.io/" target="_blank">Personal website</a>  
									<br>	
									</div>
									<p class='talk-list'>
									<b> Talk title:</b> Deformable Object Manipulation: Fundamental challenges and promising applications <br>
									</p>
							  </div>
							</div>

							<hr style="width:80%;text-align:left;margin-left:5">




					</section>

					<!-- org -->
					<section id="org" class="wrapper style3 spotlights">
						<div class="inner">
							<h2>Organizers (alphabetical order)</h2>
							<ul>
							  
							  <li>Daniel Seita, Carnegie Mellon University, USA</li>
							<li> Martina Lippi, Roma Tre University, Italy</li>
							  <li>Michael C. Welle, KTH Royal Institute of Technology, Sweden</li>			
							  <li>Fangyi Zhang, Queensland University of Technology (QUT), Australia</li>			  
							  
							</ul>

							<h2>Co-Organizers</h2>
							<ul>
							  <li>Hang Yin, KTH Royal Institute of Technology, Sweden</li>
							  <li>Danica Kragic, KTH Royal Institute of Technology, Sweden</li>
							  <li> Alessandro Marino, University of Cassino and Southern Lazio, Italy</li>
							  <li>David Held, Carnegie Mellon University, USA</li>
							  <li> Peter Corke, Queensland University of Technology (QUT), Australia</li>
							  
							</ul>
							
						


					</section>



					<!-- collaberations -->
					<!--section id="collab" class="wrapper style4 fade-up">
						<div class="inner">
							<h2>Links</h2>
							<ul>
							<li>
							  <b>Conference website:</b> Link to the conference website <a href="https://www.ieee-icra.org/">https://www.ieee-icra.org/</a>
							</li>
							</ul>
						</div>
					</section-->

							

					
					<!-- contact -->
					<section id="contact" class="wrapper style1 fade-up">
						<div class="inner">
							<h2>Contact</h2>
							 <p> If you have any questions please contact Daniel Seita at the email: <b>dseita AT andrew DOT cmu DOT edu </b>  </p>
							
							
										
							
						</div>
					</section>




			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style1-alt">
				<div class="inner">
					<ul>
					<li>
					The workshop has been endorsed by IEEE RAS Technical Committee on Computer and Robot Vision, IEEE RAS Technical Committee on Robotic Hands, Grasping, and Manipulation, and IEEE RAS Technical Committee on Robot Learning

					</li>
					<li>
					Participants are required to abide by the <a href="https://www.ieee-ras.org/about-ras/diversity-page/ieee-ras-code-of-conduct" target="_blank">IEEE RAS Code of Conduct</a>
					</li>
					
					</ul>	
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
